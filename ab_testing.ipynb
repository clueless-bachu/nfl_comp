{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/kaggle/input/timm-0-6-9/pytorch-image-models-master')\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from helper import *\n",
    "tqdm.pandas()\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "import timm\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "import torch\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from multiprocessing import Pool\n",
    "import random\n",
    "import cv2\n",
    "from math import ceil\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "tqdm.pandas()\n",
    "from glob import glob\n",
    "print('Done 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.4 ms, sys: 12.1 ms, total: 48.5 ms\n",
      "Wall time: 52.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "helmet_data= pd.read_csv('./test_baseline_helmets.csv')\n",
    "tracking_data = pd.read_csv('./test_player_tracking.csv')\n",
    "labels = pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 204 ms, sys: 36.1 ms, total: 240 ms\n",
      "Wall time: 241 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "label_exp = expand_contact_id(labels)\n",
    "use_cols = [\n",
    "    'x_position', 'y_position', 'speed', 'distance',\n",
    "    'direction', 'orientation', 'acceleration', 'sa',\n",
    "    'team', 'position'\n",
    "]\n",
    "combined_df = create_features(label_exp, tracking_data, use_cols=use_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bboxes_details(frame, player1, player2, game_play, view):\n",
    "    '''\n",
    "    takes each row in comined_df and adds the required bbox information\n",
    "    (may need more processing to convert to correct datatype)\n",
    "    '''\n",
    "    bboxes = []\n",
    "    window = 24\n",
    "    query = f\"frame >= {frame-window}  and frame <= {frame+window} and game_play == '{game_play}'\"\n",
    "    if player2 == 'G':\n",
    "        query += f\"  and nfl_player_id in ({player1}, 'G')\"\n",
    "    else:\n",
    "        query += f\"  and nfl_player_id in ({player1}, {player2})\"\n",
    "    filt = helmet_data.query(query)\n",
    "\n",
    "    tmp = filt[filt[\"view\"] == view]\n",
    "    tmp = tmp.groupby('frame')[['left','width','top','height']].mean()\n",
    "    tmp['centre_x'] = tmp['left'] + tmp['width']/2\n",
    "    tmp['centre_y'] = tmp['top'] + tmp['height']/2\n",
    "    frame_list = tmp.index # these are the available frames\n",
    "    for fr in range(frame - window, frame + window + 1):\n",
    "        if fr in frame_list:\n",
    "            x, y = tmp.loc[fr][['centre_x','centre_y']]\n",
    "            bboxes.append([x, y])\n",
    "        else:\n",
    "            bboxes.append([np.nan, np.nan])\n",
    "    \n",
    "    bboxes = pd.DataFrame(np.array(bboxes)).interpolate(limit_direction='both').values\n",
    "    return np.array(bboxes)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6631/6631 [01:11<00:00, 92.75it/s] \n",
      "100%|██████████| 6631/6631 [01:13<00:00, 89.72it/s] \n"
     ]
    }
   ],
   "source": [
    "combined_df['bbox_endzone'] = combined_df.progress_apply(\n",
    "lambda x: add_bboxes_details(x['frame'],x['nfl_player_id_1'],x['nfl_player_id_2'],x['game_play'], 'Endzone'),\n",
    "axis=1\n",
    "    )\n",
    "combined_df['bbox_sideline'] = combined_df.progress_apply(\n",
    "lambda x: add_bboxes_details(x['frame'],x['nfl_player_id_1'],x['nfl_player_id_2'],x['game_play'], 'Sideline'),\n",
    "axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path, cx, cy, view, aug):\n",
    "    img_new = np.zeros((1, 256, 256), dtype=np.float32)\n",
    "    # print(path)\n",
    "    if os.path.isfile(path):\n",
    "        if view == 'Endzone':\n",
    "            img = cv2.imread(path, 0)[\n",
    "                cy-76:cy+180, cx-128:cx+128].copy()\n",
    "            img_new[0, :img.shape[0], :img.shape[1]] = img\n",
    "        else:\n",
    "            img = cv2.imread(path, 0)[\n",
    "                cy-128:cy+128, cx-128:cx+128].copy()\n",
    "            img_new[0, :img.shape[0], :img.shape[1]] = img\n",
    "\n",
    "    return aug(image=img_new.transpose(1, 2, 0))['image'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'seed': 42,\n",
    "    'num_workers':0,\n",
    "    'batch_size': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_aug = A.Compose([\n",
    "    A.Normalize(mean=[0.], std=[1.]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "categorical_data_for_fitting = [\n",
    "    ['home', 'CB', 'home', 'CB', ] ,\n",
    "    ['home', 'DE', 'home', 'DE', ],\n",
    "    ['home', 'FS', 'home', 'FS', ],\n",
    "    ['home', 'TE', 'home', 'TE', ] ,\n",
    "    ['home', 'ILB', 'home', 'ILB', ],\n",
    "    ['home', 'OLB', 'home', 'OLB', ],\n",
    "    ['home', 'T', 'home', 'T', ],\n",
    "    ['home', 'G', 'home', 'G', ] ,\n",
    "    ['home', 'C', 'home', 'C', ] ,\n",
    "    ['home', 'QB', 'home', 'QB', ],\n",
    "    ['home', 'WR', 'home', 'WR', ],\n",
    "    ['home', 'RB', 'home', 'RB', ],\n",
    "    ['home', 'NT', 'home', 'NT', ],\n",
    "    ['home', 'DT', 'home', 'DT', ],\n",
    "    ['home', 'MLB', 'home', 'MLB', ],\n",
    "    ['home', 'SS', 'home', 'SS', ] ,\n",
    "    ['home', 'OT', 'home', 'OT', ],\n",
    "    ['home', 'LB', 'home', 'LB', ],\n",
    "    ['home', 'OG', 'home', 'OG', ] ,\n",
    "    ['home', 'SAF', 'home', 'SAF', ],\n",
    "    ['home', 'DB', 'home', 'DB', ] ,\n",
    "    ['home', 'LS', 'home', 'LS', ] ,\n",
    "    ['home', 'K', 'home', 'K', ],\n",
    "    ['home', 'P', 'home', 'P', ],\n",
    "    ['home', 'FB', 'home', 'FB', ] ,\n",
    "    ['home', 'S', 'home', 'S', ],\n",
    "    ['home', 'DL', 'Ground', 'DL', ],\n",
    "    ['away', 'HB', 'away', 'HB', ],\n",
    "    ['away', 'HB', 'away', 'Ground', ],\n",
    "]\n",
    "    \n",
    "one_hot = OneHotEncoder()\n",
    "one_hot.fit(categorical_data_for_fitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset1(Dataset):\n",
    "    def __init__(self, df, aug, one_hot_transform, train=False, feature_cols=['rel_pos_x',\n",
    "     'rel_pos_y', 'rel_pos_mag', 'rel_pos_ori', 'rel_speed_x', 'rel_speed_y',\n",
    "     'rel_speed_mag', 'rel_speed_ori', 'rel_acceleration_x',\n",
    "     'rel_acceleration_y', 'rel_acceleration_mag', 'rel_acceleration_ori',\n",
    "     'G_flug', 'orientation_1', 'orientation_2']):\n",
    "\n",
    "        self.df = df\n",
    "        self.features = feature_cols\n",
    "        self.aug = aug\n",
    "        self.train = train\n",
    "        self.one_hot_transform = one_hot_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return ceil(len(self.df)/CFG['batch_size'])\n",
    "\n",
    "    def get_rows(self, lnum, unum):\n",
    "        lnum = lnum % len(self.df)\n",
    "        unum = unum % len(self.df)\n",
    "\n",
    "        if lnum < unum:\n",
    "            return self.df[lnum:unum]\n",
    "        else:\n",
    "            if self.train:\n",
    "                return pd.concat([self.df[lnum:], self.df[:unum]])\n",
    "            else:\n",
    "                return self.df[lnum:]\n",
    "\n",
    "    def normalize_features(self, features):\n",
    "        \"\"\"\n",
    "        normalizes the features of the players\n",
    "\n",
    "       'rel_pos_x',\n",
    "       'rel_pos_y', 'rel_pos_mag', 'rel_pos_ori', 'rel_speed_x', 'rel_speed_y',\n",
    "       'rel_speed_mag', 'rel_speed_ori', 'rel_acceleration_x',\n",
    "       'rel_acceleration_y', 'rel_acceleration_mag', 'rel_acceleration_ori',\n",
    "       'G_flug', 'orientation_1', 'orientation_2'\n",
    "        \"\"\"\n",
    "        features /= 100\n",
    "        features[3] /= 3.6\n",
    "        features[7] /= 3.6\n",
    "        features[11] /= 3.6\n",
    "        features[13] /= 3.6\n",
    "        features[14] /= 3.6\n",
    "        return features\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window = 24\n",
    "        frames_to_skip = 4\n",
    "\n",
    "        row = self.get_rows(\n",
    "            idx*(CFG['batch_size']), (idx+1)*(CFG['batch_size'])).reset_index(drop=True)\n",
    "        \n",
    "        mid_frame = row['frame']\n",
    "        label = np.array(row['contact']).astype(np.float32)\n",
    "        args = []\n",
    "        for i in range(len(row)):\n",
    "            for view in ['Endzone', 'Sideline']:\n",
    "                video = row.iloc[i]['game_play'] + f'_{view}.mp4'\n",
    "                cur_mid_frame = mid_frame.iloc[i]\n",
    "                frames = [cur_mid_frame - window +\n",
    "                          i for i in range(0, 2*window+1, frames_to_skip)]\n",
    "                bbox_col = 'bbox_endzone' if view == 'Endzone' else 'bbox_sideline'\n",
    "                bboxes = row.iloc[i][bbox_col][::frames_to_skip].astype(\n",
    "                    np.int32)\n",
    "#                 print(bboxes)\n",
    "\n",
    "                if bboxes.sum() <= 0:\n",
    "                    args += [('dummy', 0, 0, view, self.aug)]*len(frames)\n",
    "                    continue\n",
    "\n",
    "                for j, frame in enumerate(frames):\n",
    "                    cx, cy = bboxes[j]\n",
    "                    path = f'./work/test_frames/{video}_{frame:04d}.jpg'\n",
    "                    args.append((path, cx, cy, view, self.aug))\n",
    "        imgs = []\n",
    "        for arg in args:\n",
    "            imgs.append(read_image(*arg))\n",
    "\n",
    "        # if __name__ == '__main__':\n",
    "        #     with Pool(CFG['num_workers']) as pool:\n",
    "        #         imgs = list(pool.starmap(read_image, args))\n",
    "        #         pool.close()\n",
    "        \n",
    "        img = torch.stack(imgs).reshape(len(row), 26, 256, 256)\n",
    "        features = np.array(row[self.features], dtype=np.float32)\n",
    "        # print(features) same till here\n",
    "        # print(row)\n",
    "        features[np.isnan(features)] = 0\n",
    "\n",
    "        \"\"\"\n",
    "        rel_pos_x                0\n",
    "        rel_pos_y                1\n",
    "        rel_pos_mag              2\n",
    "        rel_pos_ori              3\n",
    "        rel_speed_x              4\n",
    "        rel_speed_y              5\n",
    "        rel_speed_mag            6\n",
    "        rel_speed_ori            7\n",
    "        rel_acceleration_x       8\n",
    "        rel_acceleration_y       9\n",
    "        rel_acceleration_mag     10\n",
    "        rel_acceleration_ori     11 \n",
    "        \"\"\"\n",
    "        for i in range(len(row)):\n",
    "            if row.iloc[i]['G_flug']:\n",
    "                features[i, 6] = row.iloc[i]['speed_1']\n",
    "                features[i, 7] = row.iloc[i]['direction_1']\n",
    "                features[i, 10] = row.iloc[i]['acceleration_1']\n",
    "                features[i, 11] = row.iloc[i]['direction_1']\n",
    "\n",
    "                features[i, 4] = row.iloc[i]['speed_1'] * \\\n",
    "                    np.sin(row.iloc[i]['direction_1']*np.pi/180)\n",
    "                features[i, 5] = row.iloc[i]['speed_1'] * \\\n",
    "                    np.cos(row.iloc[i]['direction_1']*np.pi/180)\n",
    "                features[i, 8] = row.iloc[i]['acceleration_1'] * \\\n",
    "                    np.sin(row.iloc[i]['direction_1']*np.pi/180)\n",
    "                features[i, 9] = row.iloc[i]['acceleration_1'] * \\\n",
    "                    np.cos(row.iloc[i]['direction_1']*np.pi/180)\n",
    "            # print(\"unnormalized\",features)\n",
    "            features[i, :] = self.normalize_features(features[i])\n",
    "        # print(features)\n",
    "\n",
    "        team_pos = np.array(\n",
    "            row[['team_1', 'position_1', 'team_2', 'position_2']].fillna('Ground'))\n",
    "        team_pos = self.one_hot_transform.transform(team_pos).toarray()\n",
    "        return img, torch.from_numpy(np.hstack((features, team_pos)).astype(np.float32)), torch.as_tensor(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 796.00it/s]\n"
     ]
    }
   ],
   "source": [
    "video2helmets = {}\n",
    "test_helmets_new = helmet_data.set_index('video')\n",
    "for video in tqdm(helmet_data.video.unique()):\n",
    "    video2helmets[video] = test_helmets_new.loc[video].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 239.05it/s]\n"
     ]
    }
   ],
   "source": [
    "video2frames = {}\n",
    "test_video_metadata = pd.read_csv(\"./test_video_metadata.csv\")\n",
    "for game_play in tqdm(test_video_metadata.game_play.unique()):\n",
    "    for view in ['Endzone', 'Sideline']:\n",
    "        video = game_play + f'_{view}.mp4'\n",
    "        video2frames[video] = max(list(map(lambda x:int(x.split('_')[-1].split('.')[0]), \\\n",
    "                                           glob(f'./work/test_frames/{video}*'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset2(Dataset):\n",
    "    def __init__(self, df, aug=valid_aug, mode='test', transform=one_hot):\n",
    "        self.df = df\n",
    "        self.frame = df.frame.values\n",
    "        feature_cols = ['rel_pos_x','rel_pos_y', 'rel_pos_mag', 'rel_pos_ori', 'rel_speed_x', 'rel_speed_y',\n",
    "            'rel_speed_mag', 'rel_speed_ori', 'rel_acceleration_x', 'rel_acceleration_y', 'rel_acceleration_mag',\n",
    "            'rel_acceleration_ori', 'G_flug', 'orientation_1', 'orientation_2']\n",
    "        self.feature = df[feature_cols].fillna(0).values\n",
    "        self.players = df[['nfl_player_id_1','nfl_player_id_2']].values\n",
    "        self.game_play = df.game_play.values\n",
    "        self.aug = aug\n",
    "        self.mode = mode\n",
    "        self.one_hot_transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    # @lru_cache(1024)\n",
    "    # def read_img(self, path):\n",
    "    #     return cv2.imread(path, 0)\n",
    "    def normalize_features(self, features):\n",
    "        \"\"\"\n",
    "        normalizes the features of the players\n",
    "\n",
    "       'rel_pos_x',\n",
    "       'rel_pos_y', 'rel_pos_mag', 'rel_pos_ori', 'rel_speed_x', 'rel_speed_y',\n",
    "       'rel_speed_mag', 'rel_speed_ori', 'rel_acceleration_x',\n",
    "       'rel_acceleration_y', 'rel_acceleration_mag', 'rel_acceleration_ori',\n",
    "       'G_flug', 'orientation_1', 'orientation_2'\n",
    "        \"\"\"\n",
    "        features /= 100\n",
    "        features[3] /= 3.6\n",
    "        features[7] /= 3.6\n",
    "        features[11] /= 3.6\n",
    "        features[13] /= 3.6\n",
    "        features[14] /= 3.6\n",
    "        return features\n",
    "   \n",
    "    def __getitem__(self, idx):   \n",
    "        window = 24\n",
    "        frame = self.frame[idx]\n",
    "        \n",
    "#         if self.mode == 'train':\n",
    "#             frame = frame + random.randint(-6, 6)\n",
    "\n",
    "        players = []\n",
    "        for p in self.players[idx]:\n",
    "            if p == 'G':\n",
    "                players.append(p)\n",
    "            else:\n",
    "                players.append(int(p))\n",
    "        \n",
    "        imgs = []\n",
    "        for view in ['Endzone', 'Sideline']:\n",
    "            video = self.game_play[idx] + f'_{view}.mp4'\n",
    "\n",
    "            tmp = video2helmets[video]\n",
    "#             tmp = tmp.query('@frame-@window<=frame<=@frame+@window')\n",
    "            tmp[tmp['frame'].between(frame-window, frame+window)]\n",
    "            tmp = tmp[tmp.nfl_player_id.isin(players)]#.sort_values(['nfl_player_id', 'frame'])\n",
    "            tmp_frames = tmp.frame.values\n",
    "            tmp = tmp.groupby('frame')[['left','width','top','height']].mean()\n",
    "#0.002s\n",
    "\n",
    "            bboxes = []\n",
    "            for f in range(frame-window, frame+window+1, 1):\n",
    "                if f in tmp_frames:\n",
    "                    x, w, y, h = tmp.loc[f][['left','width','top','height']]\n",
    "                    bboxes.append([x, w, y, h])\n",
    "                else:\n",
    "                    bboxes.append([np.nan, np.nan, np.nan, np.nan])\n",
    "            bboxes = pd.DataFrame(bboxes).interpolate(limit_direction='both').values\n",
    "            bboxes = bboxes[::4]\n",
    "\n",
    "            if bboxes.sum() > 0:\n",
    "                flag = 1\n",
    "            else:\n",
    "                flag = 0\n",
    "#0.03s\n",
    "                    \n",
    "            for i, f in enumerate(range(frame-window, frame+window+1, 4)):\n",
    "                img_new = np.zeros((256, 256), dtype=np.float32)\n",
    "\n",
    "                if flag == 1 and f <= video2frames[video]:\n",
    "                    # print(f'/kaggle/work/frames/{video}_{f:04d}.jpg')\n",
    "                    img = cv2.imread(f'./work/test_frames/{video}_{f:04d}.jpg', 0)\n",
    "\n",
    "                    x, w, y, h = bboxes[i]\n",
    "                    if view == 'Endzone':\n",
    "                        img = img[int(y+h/2)-76:int(y+h/2)+180,int(x+w/2)-128:int(x+w/2)+128].copy()\n",
    "                    else:\n",
    "                        img = img[int(y+h/2)-128:int(y+h/2)+128,int(x+w/2)-128:int(x+w/2)+128].copy()\n",
    "                    img_new[:img.shape[0], :img.shape[1]] = img\n",
    "                    \n",
    "                imgs.append(img_new)\n",
    "\n",
    "        \n",
    "        features = np.float32(self.feature[idx])\n",
    "        print(features.shape)\n",
    "        # print(\"this is i: \",i)\n",
    "        if self.df.iloc[idx]['G_flug']:\n",
    "                features[ 6] = self.df.iloc[idx]['speed_1']\n",
    "                features[7] = self.df.iloc[idx]['direction_1']\n",
    "                features[10] = self.df.iloc[idx]['acceleration_1']\n",
    "                features[11] = self.df.iloc[idx]['direction_1']\n",
    "\n",
    "                features[4] = self.df.iloc[idx]['speed_1'] * \\\n",
    "                    np.sin(self.df.iloc[idx]['direction_1']*np.pi/180)\n",
    "                features[5] = self.df.iloc[idx]['speed_1'] * \\\n",
    "                    np.cos(self.df.iloc[idx]['direction_1']*np.pi/180)\n",
    "                features[8] = self.df.iloc[idx]['acceleration_1'] * \\\n",
    "                    np.sin(self.df.iloc[idx]['direction_1']*np.pi/180)\n",
    "                features[9] = self.df.iloc[idx]['acceleration_1'] * \\\n",
    "                    np.cos(self.df.iloc[idx]['direction_1']*np.pi/180)\n",
    "        # print(\"unnormalized\",features)\n",
    "        features = self.normalize_features(features)\n",
    "        # print(features)\n",
    "\n",
    "        team_pos = np.array(\n",
    "            self.df.iloc[idx][['team_1', 'position_1', 'team_2', 'position_2']].fillna('Ground'))\n",
    "        team_pos = self.one_hot_transform.transform([team_pos]).toarray()[0]\n",
    "\n",
    "        img = np.array(imgs).transpose(1, 2, 0)    \n",
    "        img = self.aug(image=img)[\"image\"]\n",
    "        label = np.float32(self.df.contact.values[idx])\n",
    "\n",
    "        return img, torch.from_numpy(np.hstack((features, team_pos)).astype(np.float32)), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15,)\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0028, -0.0095,  0.0099,  0.4538,\n",
      "          0.0048, -0.0161,  0.0168,  0.4538,  0.0100,  0.2519,  0.0000,  0.0000,\n",
      "          1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0028, -0.0095,  0.0099,  0.4538,\n",
      "         0.0048, -0.0161,  0.0168,  0.4538,  0.0100,  0.2519,  0.0000,  0.0000,\n",
      "         1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000])\n"
     ]
    }
   ],
   "source": [
    "test1 = MyDataset1(combined_df, aug=valid_aug, train=False, one_hot_transform=one_hot)\n",
    "test2 = MyDataset2(combined_df, aug=valid_aug, transform=one_hot)\n",
    "\n",
    "i = 13\n",
    "img1, feat1, label1 = test1[i]\n",
    "img2, feat2, label2 = test2[i]\n",
    "\n",
    "print(feat1)\n",
    "print(feat2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validator1():\n",
    "    def __init__(self, df, aug, transform, verbose=True):\n",
    "        self.test_set = MyDataset1(\n",
    "            df, aug=aug, train=False, one_hot_transform=transform)\n",
    "        self.verbose = verbose\n",
    "        print(df.iloc[-1])\n",
    "        # self.criterion = criterion\n",
    "\n",
    "    def validate(self, model):\n",
    "        y_hat = []\n",
    "        # y = []\n",
    "        # loss = 0\n",
    "        # logger.debug(\"converting testloader to iter\")\n",
    "        # logger.debug(\"done converting testloader to iter\")\n",
    "        model.eval()\n",
    "\n",
    "        print(f\"ceil: {ceil(len(self.test_set.df)/CFG['batch_size'])}\")\n",
    "        with torch.no_grad():\n",
    "            for iteration in tqdm(range(ceil(len(self.test_set.df)/CFG['batch_size']))):\n",
    "\n",
    "                imgs, features, labels = self.test_set[iteration]\n",
    "                imgs = imgs.to(0, non_blocking=True)\n",
    "                features = features.to(0, non_blocking=True)\n",
    "                print(features[-1])\n",
    "                # labels = labels.to(0, non_blocking=True)\n",
    "\n",
    "                preds = model(imgs, features)\n",
    "                print(preds)\n",
    "\n",
    "                # loss += self.criterion(preds,\n",
    "                #                        labels).cpu().detach().numpy().ravel()[0]\n",
    "                # y.append(labels.cpu().detach().numpy())\n",
    "                y_hat.append(preds.cpu().detach().numpy())\n",
    "\n",
    "            # logger.debug(f\"Combined val labels:\\n{y}\")\n",
    "            # logger.debug(f\"Combined val preds:\\n{y_hat}\")\n",
    "            # y = np.hstack(y)\n",
    "            y_hat = np.hstack(y_hat)\n",
    "            # logger.debug(f\"Combined val labels:\\n{y}\")\n",
    "            # logger.debug(f\"Combined val preds:\\n{y_hat}\")\n",
    "\n",
    "            # loss = loss/CFG['batch_size']\n",
    "\n",
    "            # threshs = np.linspace(0.001, 0.999, 10000)\n",
    "\n",
    "            # mat_cors = []\n",
    "            # best = 0\n",
    "            # best_thresh = -1\n",
    "            # for thresh in threshs:\n",
    "            #     _, val_mathew_corr,  _, _, _ = get_stats(\n",
    "            #         loss, y, y_hat, cur_iter=f\"Val\", thresh=thresh)\n",
    "            #     mat_cors.append(val_mathew_corr)\n",
    "            #     if val_mathew_corr > best:\n",
    "            #         best = val_mathew_corr\n",
    "            #         best_thresh = thresh\n",
    "            # tb.add_scalar(\"Val Loss\", loss, iteration)\n",
    "            # tb.add_scalar(\"Val  Accuracy\", val_acc,\n",
    "            #               iteration)\n",
    "            # tb.add_scalar(\"Val Mathew Correlation\",\n",
    "            #               val_mathew_corr, iteration)\n",
    "            # if self.verbose:\n",
    "            #     logger.info(f\"{stats}\")\n",
    "\n",
    "        return y_hat #mat_cors, threshs, best, best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validator2():\n",
    "    def __init__(self, df, aug, transform, verbose=True):\n",
    "        self.test_set = MyDataset2(\n",
    "            df, aug=aug, transform=transform)\n",
    "        self.test_loader = DataLoader(self.test_set, batch_size=CFG['batch_size'], shuffle=False,\\\n",
    "                                      num_workers=CFG['num_workers'], pin_memory=True)\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        print(df.iloc[-1])\n",
    "\n",
    "    def validate(self, model):\n",
    "        # logger.debug(\"converting testloader to iter\")\n",
    "        # logger.debug(\"done converting testloader to iter\")\n",
    "        model.eval()\n",
    "        y_pred = []\n",
    "\n",
    "        print(len(self.test_loader))\n",
    "        with torch.no_grad():\n",
    "            tk = tqdm(self.test_loader, total=len(self.test_loader))\n",
    "            for step, batch in enumerate(tk):\n",
    "                img, feature, label = [x.to(0) for x in batch]\n",
    "                print(feature[-1])\n",
    "                output = model(img, feature).squeeze(-1)\n",
    "                print(output)\n",
    "                y_pred.extend(output.cpu().numpy())\n",
    "\n",
    "        y_pred = np.array(y_pred)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.backbone = timm.create_model(\n",
    "            'resnet18', pretrained=False, num_classes=250, in_chans=26)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(77, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        self.fc = nn.Linear(64+250, 1)\n",
    "\n",
    "    def forward(self, img, feature):\n",
    "        img = self.backbone(img)\n",
    "        feature = self.mlp(feature)\n",
    "        y = torch.sigmoid(self.fc(torch.cat([img, feature], dim=1)))\n",
    "        return y.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(26, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (fc): Linear(in_features=512, out_features=250, bias=True)\n",
       "  )\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=77, out_features=128, bias=True)\n",
       "    (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=314, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('./model_checkpoints/baseline_3_2023-02-06-08-19-29/best_model.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contact_id                                         58168_003392_0_37084_G\n",
      "contact                                                                 0\n",
      "game_play                                                    58168_003392\n",
      "step                                                                    0\n",
      "nfl_player_id_1                                                     37084\n",
      "nfl_player_id_2                                                         G\n",
      "x_position_1                                                         41.9\n",
      "y_position_1                                                        20.08\n",
      "speed_1                                                              0.54\n",
      "distance_1                                                           0.06\n",
      "direction_1                                                        252.69\n",
      "orientation_1                                                      262.31\n",
      "acceleration_1                                                       0.92\n",
      "sa_1                                                                  0.9\n",
      "team_1                                                               away\n",
      "position_1                                                             DE\n",
      "x_position_2                                                          NaN\n",
      "y_position_2                                                          NaN\n",
      "speed_2                                                               NaN\n",
      "distance_2                                                            NaN\n",
      "direction_2                                                           NaN\n",
      "orientation_2                                                         NaN\n",
      "acceleration_2                                                        NaN\n",
      "sa_2                                                                  NaN\n",
      "team_2                                                                NaN\n",
      "position_2                                                            NaN\n",
      "rel_pos_x                                                             NaN\n",
      "rel_pos_y                                                             NaN\n",
      "rel_pos_mag                                                           NaN\n",
      "rel_pos_ori                                                           NaN\n",
      "rel_speed_x                                                           NaN\n",
      "rel_speed_y                                                           NaN\n",
      "rel_speed_mag                                                         NaN\n",
      "rel_speed_ori                                                         NaN\n",
      "rel_acceleration_x                                                    NaN\n",
      "rel_acceleration_y                                                    NaN\n",
      "rel_acceleration_mag                                                  NaN\n",
      "rel_acceleration_ori                                                  NaN\n",
      "G_flug                                                               True\n",
      "frame                                                                 300\n",
      "bbox_endzone            [[405.0, 325.5], [405.0, 325.5], [405.0, 325.5...\n",
      "bbox_sideline           [[490.0, 477.0], [490.0, 477.0], [490.0, 477.0...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "valer1 = Validator1(combined_df[1:2], aug=valid_aug, transform=one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contact_id                                         58168_003392_0_37084_G\n",
      "contact                                                                 0\n",
      "game_play                                                    58168_003392\n",
      "step                                                                    0\n",
      "nfl_player_id_1                                                     37084\n",
      "nfl_player_id_2                                                         G\n",
      "x_position_1                                                         41.9\n",
      "y_position_1                                                        20.08\n",
      "speed_1                                                              0.54\n",
      "distance_1                                                           0.06\n",
      "direction_1                                                        252.69\n",
      "orientation_1                                                      262.31\n",
      "acceleration_1                                                       0.92\n",
      "sa_1                                                                  0.9\n",
      "team_1                                                               away\n",
      "position_1                                                             DE\n",
      "x_position_2                                                          NaN\n",
      "y_position_2                                                          NaN\n",
      "speed_2                                                               NaN\n",
      "distance_2                                                            NaN\n",
      "direction_2                                                           NaN\n",
      "orientation_2                                                         NaN\n",
      "acceleration_2                                                        NaN\n",
      "sa_2                                                                  NaN\n",
      "team_2                                                                NaN\n",
      "position_2                                                            NaN\n",
      "rel_pos_x                                                             NaN\n",
      "rel_pos_y                                                             NaN\n",
      "rel_pos_mag                                                           NaN\n",
      "rel_pos_ori                                                           NaN\n",
      "rel_speed_x                                                           NaN\n",
      "rel_speed_y                                                           NaN\n",
      "rel_speed_mag                                                         NaN\n",
      "rel_speed_ori                                                         NaN\n",
      "rel_acceleration_x                                                    NaN\n",
      "rel_acceleration_y                                                    NaN\n",
      "rel_acceleration_mag                                                  NaN\n",
      "rel_acceleration_ori                                                  NaN\n",
      "G_flug                                                               True\n",
      "frame                                                                 300\n",
      "bbox_endzone            [[405.0, 325.5], [405.0, 325.5], [405.0, 325.5...\n",
      "bbox_sideline           [[490.0, 477.0], [490.0, 477.0], [490.0, 477.0...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "valer2 =  Validator2(combined_df[1:2], aug=valid_aug, transform=one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ceil: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "     nan    nan   1.   262.31    nan]]\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000, -0.0052, -0.0016,  0.0054,  0.7019,\n",
      "        -0.0088, -0.0027,  0.0092,  0.7019,  0.0100,  0.7286,  0.0000,  1.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000], device='cuda:0')\n",
      "tensor([0.8157], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = valer1.validate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     1.   262.31   0.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7061/2434344834.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvaler2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_7061/3906746808.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nfl_comp/lib/python3.9/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nfl_comp/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nfl_comp/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nfl_comp/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nfl_comp/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7061/206411649.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'G_flug'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'speed_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'direction_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nfl_comp/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nfl_comp/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nfl_comp/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1555\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1557\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "y_pred2 = valer2.validate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.67256945, 0.81572026, 0.12307185], dtype=float32),\n",
       " array([0.67256945, 0.8845575 , 0.12307185], dtype=float32))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1[:3], y_pred2[:3],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fin1 = y_pred1 > 0.5\n",
    "y_fin2 = y_pred2 > 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2597"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_fin1 != y_fin2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6631,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_fin2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfl_comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e0971b6e4c6e31323d9ee278a729b5ea8905a211b067f5c5125d28ccbdd03cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
