{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "import logging\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "# from multiprocessing import Pool, set_start_method\n",
    "import albumentations as A\n",
    "import timm\n",
    "from datetime import datetime\n",
    "from itertools import cycle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import cv2\n",
    "from math import ceil\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'seed': 42,\n",
    "    'test_size': 1000,\n",
    "    'lr': 1,\n",
    "    'use_multi': False,\n",
    "    'num_workers': 8,\n",
    "    'batch_size': 64,\n",
    "    'iterations': 1,\n",
    "    'val_wait': 1,\n",
    "    'scheduler_patience': 100,\n",
    "    'saver_mode': 'all',\n",
    "    'es_patience': 2,\n",
    "    'rop_factor': 0.5,\n",
    "    'rop_patience': 100,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_csv('./final_data2.csv')\n",
    "df['bbox_endzone'] = df['bbox_endzone'].apply(process_bbox)\n",
    "df['bbox_sideline'] = df['bbox_sideline'].apply(process_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data_for_fitting = [\n",
    "    ['home', 'CB', 'home', 'CB', ] ,\n",
    "    ['home', 'DE', 'home', 'DE', ],\n",
    "    ['home', 'FS', 'home', 'FS', ],\n",
    "    ['home', 'TE', 'home', 'TE', ] ,\n",
    "    ['home', 'ILB', 'home', 'ILB', ],\n",
    "    ['home', 'OLB', 'home', 'OLB', ],\n",
    "    ['home', 'T', 'home', 'T', ],\n",
    "    ['home', 'G', 'home', 'G', ] ,\n",
    "    ['home', 'C', 'home', 'C', ] ,\n",
    "    ['home', 'QB', 'home', 'QB', ],\n",
    "    ['home', 'WR', 'home', 'WR', ],\n",
    "    ['home', 'RB', 'home', 'RB', ],\n",
    "    ['home', 'NT', 'home', 'NT', ],\n",
    "    ['home', 'DT', 'home', 'DT', ],\n",
    "    ['home', 'MLB', 'home', 'MLB', ],\n",
    "    ['home', 'SS', 'home', 'SS', ] ,\n",
    "    ['home', 'OT', 'home', 'OT', ],\n",
    "    ['home', 'LB', 'home', 'LB', ],\n",
    "    ['home', 'OG', 'home', 'OG', ] ,\n",
    "    ['home', 'SAF', 'home', 'SAF', ],\n",
    "    ['home', 'DB', 'home', 'DB', ] ,\n",
    "    ['home', 'LS', 'home', 'LS', ] ,\n",
    "    ['home', 'K', 'home', 'K', ],\n",
    "    ['home', 'P', 'home', 'P', ],\n",
    "    ['home', 'FB', 'home', 'FB', ] ,\n",
    "    ['home', 'S', 'home', 'S', ],\n",
    "    ['home', 'DL', 'Ground', 'DL', ],\n",
    "    ['away', 'HB', 'away', 'HB', ],\n",
    "    ['away', 'HB', 'away', 'Ground', ],\n",
    "]\n",
    "    \n",
    "one_hot = OneHotEncoder()\n",
    "one_hot.fit(categorical_data_for_fitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot.transform(categorical_data_for_fitting).toarray()\n",
    "\n",
    "a = np.array(categorical_data_for_fitting)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(CFG['seed'])\n",
    "val_plays = np.random.choice(df['game_play'].unique(), size=2)\n",
    "val_set = df.apply(lambda row: row[df['game_play'].isin(val_plays)]).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_aug = A.Compose([\n",
    "        A.Normalize(mean=[0.], std=[1.]),\n",
    "        ToTensorV2()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, aug, one_hot_transform, feature_cols=['rel_pos_x',\n",
    "                                                                 'rel_pos_y', 'rel_pos_mag', 'rel_pos_ori', 'rel_speed_x', 'rel_speed_y',\n",
    "                                                                 'rel_speed_mag', 'rel_speed_ori', 'rel_acceleration_x',\n",
    "                                                                 'rel_acceleration_y', 'rel_acceleration_mag', 'rel_acceleration_ori',\n",
    "                                                                 'G_flug', 'orientation_1', 'orientation_2']):\n",
    "\n",
    "        self.df = df\n",
    "        self.features = feature_cols\n",
    "        self.aug = aug\n",
    "        self.one_hot_transform = one_hot_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def normalize_features(self, features):\n",
    "        \"\"\"\n",
    "        normalizes the features of the players\n",
    "\n",
    "       'rel_pos_x',\n",
    "       'rel_pos_y', 'rel_pos_mag', 'rel_pos_ori', 'rel_speed_x', 'rel_speed_y',\n",
    "       'rel_speed_mag', 'rel_speed_ori', 'rel_acceleration_x',\n",
    "       'rel_acceleration_y', 'rel_acceleration_mag', 'rel_acceleration_ori',\n",
    "       'G_flug', 'orientation_1', 'orientation_2'\n",
    "        \"\"\"\n",
    "        features /= 100\n",
    "        features[3] /= 3.6\n",
    "        features[7] /= 3.6\n",
    "        features[11] /= 3.6\n",
    "        features[13] /= 3.6\n",
    "        features[14] /= 3.6\n",
    "        return features\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window = 24\n",
    "        frames_to_skip = 4\n",
    "\n",
    "        row = self.df.iloc[idx]\n",
    "        mid_frame = row['frame']\n",
    "\n",
    "        label = float(row['contact'])\n",
    "        imgs = []\n",
    "        for view in ['Endzone', 'Sideline']:\n",
    "            video = row['game_play'] + f'_{view}.mp4'\n",
    "            frames = [mid_frame - window +\n",
    "                      i for i in range(0, 2*window+1, frames_to_skip)]\n",
    "\n",
    "            bbox_col = 'bbox_endzone' if view == 'Endzone' else 'bbox_sideline'\n",
    "            bboxes = row[bbox_col][::frames_to_skip].astype(np.int32)\n",
    "\n",
    "            if bboxes.sum() <= 0:\n",
    "                imgs += [np.zeros((256, 256), dtype=np.float32)]*len(frames)\n",
    "                continue\n",
    "\n",
    "            for i, frame in enumerate(frames):\n",
    "                img_new = np.zeros((256, 256), dtype=np.float32)\n",
    "                cx, cy = bboxes[i]\n",
    "                path = f'./work/train_frames/{video}_{frame:04d}.jpg'\n",
    "                if os.path.isfile(path):\n",
    "                    img_new = np.zeros((256, 256), dtype=np.float32)\n",
    "                    if view == 'Endzone':\n",
    "                        img = cv2.imread(path, 0)[\n",
    "                            cy-76:cy+180, cx-128:cx+128].copy()\n",
    "                        img_new[:img.shape[0], :img.shape[1]] = img\n",
    "                    else:\n",
    "                        img = cv2.imread(path, 0)[\n",
    "                            cy-128:cy+128, cx-128:cx+128].copy()\n",
    "                        img_new[:img.shape[0], :img.shape[1]] = img\n",
    "                imgs.append(img_new)\n",
    "\n",
    "        img = np.array(imgs).transpose(1, 2, 0)\n",
    "        img = self.aug(image=img)[\"image\"]\n",
    "\n",
    "        features = np.array(row[self.features], dtype=np.float32)\n",
    "        features[np.isnan(features)] = 0\n",
    "\n",
    "        \"\"\"\n",
    "        rel_pos_x                0\n",
    "        rel_pos_y                1\n",
    "        rel_pos_mag              2\n",
    "        rel_pos_ori              3\n",
    "        rel_speed_x              4\n",
    "        rel_speed_y              5\n",
    "        rel_speed_mag            6\n",
    "        rel_speed_ori            7\n",
    "        rel_acceleration_x       8\n",
    "        rel_acceleration_y       9\n",
    "        rel_acceleration_mag     10\n",
    "        rel_acceleration_ori     11 \n",
    "        \"\"\"\n",
    "        if row['G_flug']:\n",
    "            features[6] = row['speed_1']\n",
    "            features[7] = row['direction_1']\n",
    "            features[10] = row['acceleration_1']\n",
    "            features[11] = row['direction_1']\n",
    "\n",
    "            features[4] = row['speed_1']*np.sin(row['direction_1']*np.pi/180)\n",
    "            features[5] = row['speed_1']*np.cos(row['direction_1']*np.pi/180)\n",
    "            features[8] = row['acceleration_1'] * \\\n",
    "                np.sin(row['direction_1']*np.pi/180)\n",
    "            features[9] = row['acceleration_1'] * \\\n",
    "                np.cos(row['direction_1']*np.pi/180)\n",
    "        features = self.normalize_features(features)\n",
    "\n",
    "        team_pos = np.array(\n",
    "            row[['team_1', 'position_1', 'team_2', 'position_2']].fillna('Ground'))\n",
    "        team_pos = self.one_hot_transform.transform(\n",
    "            [team_pos]\n",
    "        ).toarray()[0]\n",
    "\n",
    "        return img, torch.from_numpy(np.hstack((features, team_pos)).astype(np.float32)), torch.as_tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_s = MyDataset(val_set, aug=valid_aug, one_hot_transform=one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, f, l = test_s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validator():\n",
    "    def __init__(self, test_df, aug, criterion, transform, verbose=True):\n",
    "        self.test_set = MyDataset(\n",
    "            test_df, aug=aug, one_hot_transform=transform)\n",
    "        self.verbose = verbose\n",
    "        self.test_loader = DataLoader(\n",
    "            self.test_set, batch_size=CFG['batch_size'], num_workers=CFG['num_workers'], shuffle=False, pin_memory=False, persistent_workers=bool(CFG['num_workers']))\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def validate(self, model):\n",
    "        y_hat = []\n",
    "        y = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in self.test_loader:\n",
    "                imgs, features, labels = batch\n",
    "\n",
    "                imgs = imgs.to(0, non_blocking=True)\n",
    "                features = features.to(0, non_blocking=True)\n",
    "                labels = labels.to(0, non_blocking=True)\n",
    "\n",
    "                preds = model(imgs, features)\n",
    "                y.append(labels.cpu().detach().numpy())\n",
    "                y_hat.append(preds.cpu().detach().numpy())\n",
    "\n",
    "            y = np.hstack(y)\n",
    "            y_hat = np.hstack(y_hat)\n",
    "            y_hat = 1/(1+ np.exp(-y_hat))\n",
    "\n",
    "            threshs = np.linspace(0.001, 0.999, 10000)\n",
    "\n",
    "            mat_cors = []\n",
    "            best = 0\n",
    "            best_thresh = -1\n",
    "            for thresh in threshs:\n",
    "                _, val_mathew_corr,  _, = get_stats(\n",
    "                    0.5, y, y_hat, cur_iter=f\"Val\", thresh=thresh)\n",
    "                mat_cors.append(val_mathew_corr)\n",
    "                if val_mathew_corr > best:\n",
    "                    best = val_mathew_corr\n",
    "                    best_thresh = thresh\n",
    "\n",
    "        return mat_cors, threshs, best, best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(loss, y, y_pred, cur_iter='val', thresh=0.5):\n",
    "    \"\"\"\n",
    "    Gets the stats for a particular batch\n",
    "    \"\"\"\n",
    "    y_hat = (y_pred > thresh)*1.0\n",
    "    mathew_corr = matthews_corrcoef(y, y_hat)\n",
    "    acc = accuracy_score(y, y_hat)\n",
    "\n",
    "    stats = f'Iteration: {cur_iter} || Loss: {loss:.5f} || mat_corr: {mathew_corr:.5f} || acc: {acc:.5f} || EOL'\n",
    "    return stats.replace(\"\\n\", \"\"),  mathew_corr, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "            \"test_df\": val_set,\n",
    "            \"aug\": valid_aug,\n",
    "            \"criterion\": nn.BCELoss(),\n",
    "            \"transform\": one_hot,\n",
    "            \"verbose\": True\n",
    "        }\n",
    "\n",
    "valer = Validator(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.backbone = timm.create_model(\n",
    "            'resnet50', pretrained=True, num_classes=250, in_chans=26)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(77, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LayerNorm(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64+250, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, feature):\n",
    "        img = self.backbone(img)\n",
    "        feature = self.mlp(feature)\n",
    "        y = self.fc(torch.cat([img, feature], dim=1))\n",
    "        return y.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./model_checkpoints/resnet50_v2_2023-02-14-00-29-19/best_model.pth')\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_cors, threshs, best, best_thresh = valer.validate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best, best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(threshs, mat_cors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/(1+ np.exp(-0.51))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfl_comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e0971b6e4c6e31323d9ee278a729b5ea8905a211b067f5c5125d28ccbdd03cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
